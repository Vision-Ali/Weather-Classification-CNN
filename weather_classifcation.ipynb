{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825640d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe164c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6862 files belonging to 11 classes.\n",
      "Using 5490 files for training.\n",
      "Found 6862 files belonging to 11 classes.\n",
      "Using 1372 files for validation.\n",
      "Classes: ['dew', 'fogsmog', 'frost', 'glaze', 'hail', 'lightning', 'rain', 'rainbow', 'rime', 'sandstorm', 'snow']\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 8s 1us/step\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "172/172 [==============================] - 65s 299ms/step - loss: 1.0110 - accuracy: 0.6559 - val_loss: 0.6674 - val_accuracy: 0.7544\n",
      "Epoch 2/30\n",
      "172/172 [==============================] - 49s 288ms/step - loss: 0.6276 - accuracy: 0.7729 - val_loss: 0.6240 - val_accuracy: 0.7631\n",
      "Epoch 3/30\n",
      "172/172 [==============================] - 49s 288ms/step - loss: 0.5676 - accuracy: 0.7958 - val_loss: 0.5944 - val_accuracy: 0.7755\n",
      "Epoch 4/30\n",
      "172/172 [==============================] - 49s 286ms/step - loss: 0.5110 - accuracy: 0.8124 - val_loss: 0.5912 - val_accuracy: 0.7711\n",
      "Epoch 5/30\n",
      "172/172 [==============================] - 49s 286ms/step - loss: 0.4815 - accuracy: 0.8215 - val_loss: 0.5328 - val_accuracy: 0.8069\n",
      "Epoch 6/30\n",
      "172/172 [==============================] - 49s 286ms/step - loss: 0.4433 - accuracy: 0.8361 - val_loss: 0.5602 - val_accuracy: 0.8039\n",
      "Epoch 7/30\n",
      "172/172 [==============================] - 53s 311ms/step - loss: 0.4154 - accuracy: 0.8463 - val_loss: 0.5150 - val_accuracy: 0.8156\n",
      "Epoch 8/30\n",
      "172/172 [==============================] - 50s 289ms/step - loss: 0.4126 - accuracy: 0.8464 - val_loss: 0.5183 - val_accuracy: 0.8178\n",
      "Epoch 9/30\n",
      "172/172 [==============================] - 49s 287ms/step - loss: 0.3772 - accuracy: 0.8668 - val_loss: 0.5549 - val_accuracy: 0.8076\n",
      "Epoch 10/30\n",
      "172/172 [==============================] - 49s 286ms/step - loss: 0.3723 - accuracy: 0.8585 - val_loss: 0.5499 - val_accuracy: 0.8105\n",
      "Epoch 11/30\n",
      "172/172 [==============================] - 50s 293ms/step - loss: 0.3519 - accuracy: 0.8709 - val_loss: 0.5845 - val_accuracy: 0.8047\n",
      "Epoch 12/30\n",
      "172/172 [==============================] - 49s 287ms/step - loss: 0.3409 - accuracy: 0.8780 - val_loss: 0.5617 - val_accuracy: 0.8090\n",
      "Epoch 13/30\n",
      "172/172 [==============================] - 50s 289ms/step - loss: 0.3279 - accuracy: 0.8747 - val_loss: 0.5979 - val_accuracy: 0.8054\n",
      "Epoch 14/30\n",
      "172/172 [==============================] - 50s 291ms/step - loss: 0.3050 - accuracy: 0.8863 - val_loss: 0.6149 - val_accuracy: 0.8156\n",
      "Epoch 15/30\n",
      "172/172 [==============================] - 50s 290ms/step - loss: 0.3137 - accuracy: 0.8832 - val_loss: 0.5486 - val_accuracy: 0.8156\n",
      "Epoch 16/30\n",
      "172/172 [==============================] - 50s 288ms/step - loss: 0.2966 - accuracy: 0.8913 - val_loss: 0.5665 - val_accuracy: 0.8222\n",
      "Epoch 17/30\n",
      "172/172 [==============================] - 53s 307ms/step - loss: 0.2840 - accuracy: 0.8933 - val_loss: 0.5860 - val_accuracy: 0.8076\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.5150 - accuracy: 0.8156\n",
      "Validation Accuracy: 0.82, Loss: 0.51\n"
     ]
    }
   ],
   "source": [
    "img_size = (224, 224) \n",
    "batch_size = 32\n",
    "path = './data/weather class/dataset'\n",
    "\n",
    "# --- Dataset ---\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a33341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize + prefetch\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.map(lambda x, y: (tf.keras.layers.Rescaling(1./255)(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (tf.keras.layers.Rescaling(1./255)(x), y))\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41338302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Transfer Learning Model ---\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "base_model.trainable = False   # freeze backbone\n",
    "\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f3b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf3a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training ---\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# --- Evaluation ---\n",
    "loss, acc = model.evaluate(val_ds)\n",
    "print(f\"Validation Accuracy: {acc:.2f}, Loss: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7559b540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "172/172 [==============================] - 72s 362ms/step - loss: 0.9026 - accuracy: 0.7000 - val_loss: 0.5423 - val_accuracy: 0.8214\n",
      "Epoch 2/20\n",
      "172/172 [==============================] - 60s 348ms/step - loss: 0.5716 - accuracy: 0.7989 - val_loss: 0.5381 - val_accuracy: 0.8214\n",
      "Epoch 3/20\n",
      "172/172 [==============================] - 59s 345ms/step - loss: 0.4788 - accuracy: 0.8333 - val_loss: 0.5128 - val_accuracy: 0.8302\n",
      "Epoch 4/20\n",
      "172/172 [==============================] - 60s 348ms/step - loss: 0.4330 - accuracy: 0.8490 - val_loss: 0.4856 - val_accuracy: 0.8440\n",
      "Epoch 5/20\n",
      "172/172 [==============================] - 59s 346ms/step - loss: 0.3957 - accuracy: 0.8672 - val_loss: 0.4708 - val_accuracy: 0.8433\n",
      "Epoch 6/20\n",
      "172/172 [==============================] - 60s 351ms/step - loss: 0.3589 - accuracy: 0.8745 - val_loss: 0.4642 - val_accuracy: 0.8491\n",
      "Epoch 7/20\n",
      "172/172 [==============================] - 61s 353ms/step - loss: 0.3181 - accuracy: 0.8863 - val_loss: 0.4552 - val_accuracy: 0.8477\n",
      "Epoch 8/20\n",
      "172/172 [==============================] - 60s 347ms/step - loss: 0.3022 - accuracy: 0.8980 - val_loss: 0.4274 - val_accuracy: 0.8557\n",
      "Epoch 9/20\n",
      "172/172 [==============================] - 59s 346ms/step - loss: 0.2811 - accuracy: 0.9067 - val_loss: 0.4253 - val_accuracy: 0.8557\n",
      "Epoch 10/20\n",
      "172/172 [==============================] - 60s 346ms/step - loss: 0.2624 - accuracy: 0.9107 - val_loss: 0.4068 - val_accuracy: 0.8615\n",
      "Epoch 11/20\n",
      "172/172 [==============================] - 60s 346ms/step - loss: 0.2447 - accuracy: 0.9169 - val_loss: 0.4127 - val_accuracy: 0.8630\n",
      "Epoch 12/20\n",
      "172/172 [==============================] - 60s 348ms/step - loss: 0.2321 - accuracy: 0.9164 - val_loss: 0.4063 - val_accuracy: 0.8564\n",
      "Epoch 13/20\n",
      "172/172 [==============================] - 60s 347ms/step - loss: 0.2089 - accuracy: 0.9299 - val_loss: 0.3970 - val_accuracy: 0.8644\n",
      "Epoch 14/20\n",
      "172/172 [==============================] - 59s 345ms/step - loss: 0.1996 - accuracy: 0.9317 - val_loss: 0.4026 - val_accuracy: 0.8601\n",
      "Epoch 15/20\n",
      "172/172 [==============================] - 59s 345ms/step - loss: 0.1953 - accuracy: 0.9333 - val_loss: 0.4043 - val_accuracy: 0.8593\n",
      "Epoch 16/20\n",
      "172/172 [==============================] - 59s 345ms/step - loss: 0.1766 - accuracy: 0.9383 - val_loss: 0.3966 - val_accuracy: 0.8622\n",
      "Epoch 17/20\n",
      "172/172 [==============================] - 60s 347ms/step - loss: 0.1645 - accuracy: 0.9448 - val_loss: 0.3983 - val_accuracy: 0.8637\n",
      "Epoch 18/20\n",
      "172/172 [==============================] - 60s 347ms/step - loss: 0.1543 - accuracy: 0.9455 - val_loss: 0.3869 - val_accuracy: 0.8659\n",
      "Epoch 19/20\n",
      "172/172 [==============================] - 60s 347ms/step - loss: 0.1506 - accuracy: 0.9492 - val_loss: 0.3898 - val_accuracy: 0.8673\n",
      "Epoch 20/20\n",
      "172/172 [==============================] - 60s 347ms/step - loss: 0.1395 - accuracy: 0.9559 - val_loss: 0.4004 - val_accuracy: 0.8630\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Unfreeze base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Re-compile with lower learning rate (important!)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),  # smaller LR\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Train again (fine-tune)\n",
    "history_finetune = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9caf99ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 2s 48ms/step - loss: 0.4004 - accuracy: 0.8630\n",
      "Final Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(val_ds)\n",
    "print(f\"Final Accuracy: {acc:.2f}\")\n",
    "\n",
    "# Save model\n",
    "model.save(\"weather_classifier.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d298bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predicted class: sandstorm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img_path = \"sample3.jpg\"  # your test image\n",
    "img = tf.keras.utils.load_img(img_path, target_size=(224,224))\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) / 255.0  # scale\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "pred_class = class_names[np.argmax(predictions)]\n",
    "\n",
    "print(\"Predicted class:\", pred_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5bb5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ffbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
